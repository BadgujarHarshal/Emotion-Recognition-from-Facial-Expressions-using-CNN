# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EYDxE8xhf5gnKP-1XEjHvxZ7xmFTniYt
"""

!pip install -q kaggle

from google.colab import files
print("üìÅ Please upload your kaggle.json file now...")
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

print("‚úÖ Kaggle setup complete.")

!kaggle datasets download -d msambare/fer2013

import zipfile, os

zip_file_path = "fer2013.zip"
extract_dir = "fer2013_dataset"

os.makedirs(extract_dir, exist_ok=True)

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("‚úÖ Dataset unzipped!")
print("üìÇ Contents of dataset folder:")
!ls {extract_dir}

import pandas as pd

csv_file_path = os.path.join(extract_dir, 'fer2013.csv')
if os.path.exists(csv_file_path):
    data = pd.read_csv(csv_file_path, nrows=5000)
    print(f"‚úÖ Partial dataset loaded: {data.shape}")
else:
    print(" Error: CSV file not found.")

import zipfile

with zipfile.ZipFile("fer2013.zip", 'r') as zip_ref:
    zip_ref.printdir()

import zipfile
import os

extract_dir = "fer2013_dataset"

with zipfile.ZipFile("fer2013.zip", 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("Contents of dataset root:")
!ls {extract_dir}
print("\nContents of train folder:")
!ls {os.path.join(extract_dir, 'train')}

import os
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

base_dir = "fer2013_dataset"
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")

img_size = (48, 48)
batch_size = 64

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    color_mode="grayscale",
    class_mode="categorical",
    batch_size=batch_size,
    subset="training"
)

val_gen = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    color_mode="grayscale",
    class_mode="categorical",
    batch_size=batch_size,
    subset="validation"
)

test_datagen = ImageDataGenerator(rescale=1./255)

test_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    color_mode="grayscale",
    class_mode="categorical",
    batch_size=batch_size,
    shuffle=False
)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)),
    BatchNormalization(),
    MaxPooling2D(2,2),
    Dropout(0.25),

    Conv2D(64, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2,2),
    Dropout(0.25),

    Conv2D(128, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2,2),
    Dropout(0.25),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')  # 7 emotion classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=20,
    callbacks=[early_stopping]
)

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('Loss')
plt.legend()
plt.show()

predictions = model.predict(test_gen)
y_pred = np.argmax(predictions, axis=1)
y_true = test_gen.classes

cm = confusion_matrix(y_true, y_pred)
class_names = list(test_gen.class_indices.keys())

plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))